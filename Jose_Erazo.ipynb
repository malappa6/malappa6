{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8cz53iDAaxC"
   },
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnryOwcYN9sN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCS8tn6zOPuW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "GLwUFR9TOeyn",
    "outputId": "59e2d184-4593-4eae-dec5-d85ca2e64c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VavM5QA7AaBr"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haj0aavu974c"
   },
   "source": [
    " # TASK 1: Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8NyyIVsrGak"
   },
   "source": [
    "Load the data and save it in appropriate variables. Display an image and its corresponding label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERLY5XTEOruh"
   },
   "outputs": [],
   "source": [
    "!unzip -q -o  \"/content/gdrive/My Drive/animal_dataset_intermediate.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fm5NX_FdQbhj"
   },
   "outputs": [],
   "source": [
    "train_path = \"animal_dataset_intermediate/train\"\n",
    "test_path = \"animal_dataset_intermediate/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wPcQ8fQQgn7"
   },
   "outputs": [],
   "source": [
    "image_files = glob(train_path+\"/*/*.jp*\")\n",
    "random.seed(33)\n",
    "random.shuffle(image_files) #shuffle images\n",
    "test_image_files = glob(test_path+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "yeFh0vGMQgq8",
    "outputId": "d49ab91f-ec34-4796-fe43-257211c47c21"
   },
   "outputs": [],
   "source": [
    "n = 0   #image number\n",
    "\n",
    "img = cv2.imread(image_files[n],1) \n",
    "cv2_imshow(img)\n",
    "print((re.search(\"\\w*(\\/)\",image_files[n].replace(\"animal_dataset_intermediate/train/\",\"\").replace(\"_train\",\"\"))[0]).replace(\"/\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLXfnHU_YbG7"
   },
   "source": [
    "Lets take a look at image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "T8r-4RMiQgtq",
    "outputId": "b37b5672-35bf-43d5-c970-c31b7a55ad83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 300, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hN8JgLOYeOB"
   },
   "source": [
    "We need to fix it to an specific value for our networks input. 224 x 224 is selected as it is a popular image size in a lot of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihB92qyER3BL"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwFg6JIIXhjI"
   },
   "source": [
    "Lets convert images to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tbk2YIz9Xf1n"
   },
   "outputs": [],
   "source": [
    "X = np.array([cv2.resize(cv2.imread(x,1),IMAGE_SIZE) for x in image_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOTAKH5sb49j"
   },
   "outputs": [],
   "source": [
    "y = np.array([(re.search(\"\\w*(\\/)\",n.replace(\"animal_dataset_intermediate/train/\",\"\").replace(\"_train\",\"\"))[0]).replace(\"/\",\"\") for n in image_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ongxSv4mX37g",
    "outputId": "c2f6610e-2334-4d35-d702-1f44b873bdf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8162, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "gwdwOl5CbBPx",
    "outputId": "21253810-266b-4533-af09-2998527653da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8162,)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7YJbgMKXFKY"
   },
   "source": [
    "# TASK 2: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9P5JWDBrEZk"
   },
   "source": [
    "Apply the required pre-processing steps on the image data. These may include scaling, converting to grayscale or anything else. Justify your decision about performing those particular pre-processing steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kf6UZ6guawmg"
   },
   "source": [
    "Lets start rescaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7Ta2hwLakl5"
   },
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghe9Ec70bB1y"
   },
   "source": [
    "Lets encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9KLvv9rfD8D"
   },
   "outputs": [],
   "source": [
    "y_dummy = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "HjFwBFJJupMO",
    "outputId": "cf044570-5302-48e1-8fde-50d323d1eb16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elefante</th>\n",
       "      <th>farfalla</th>\n",
       "      <th>mucca</th>\n",
       "      <th>pecora</th>\n",
       "      <th>scoiattolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8162 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      elefante  farfalla  mucca  pecora  scoiattolo\n",
       "0            0         0      0       0           1\n",
       "1            0         0      0       1           0\n",
       "2            0         0      0       1           0\n",
       "3            1         0      0       0           0\n",
       "4            1         0      0       0           0\n",
       "...        ...       ...    ...     ...         ...\n",
       "8157         0         0      0       1           0\n",
       "8158         1         0      0       0           0\n",
       "8159         0         0      0       0           1\n",
       "8160         0         1      0       0           0\n",
       "8161         0         0      1       0           0\n",
       "\n",
       "[8162 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpanUPqaXOUQ"
   },
   "source": [
    "# TASK 3: Building a Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pd4JU7oerCD8"
   },
   "source": [
    "Create a multi-layer perceptron, deciding on the number of layers, neurons and activation functions that should be provided. Print a summary and architecture of the model. Explain the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8qRQknVhtgc"
   },
   "outputs": [],
   "source": [
    "N, D = X.reshape(X.shape[0],-1).shape \n",
    "_, K = y_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lTPWneTyqbY"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeJicIe0htoR"
   },
   "outputs": [],
   "source": [
    "m_in = Input(shape=[D,])\n",
    "m = Dense(100,activation = \"relu\")(m_in)\n",
    "m = Dense(50,activation = \"relu\")(m)\n",
    "m = Dense(K,activation = \"softmax\")(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDElMGM6jTY9"
   },
   "outputs": [],
   "source": [
    "dense_nn = Model(inputs = m_in, outputs = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "MvUb5IMghtrp",
    "outputId": "5cd3d2f0-6ce7-4d14-a9fd-4a6e74b83491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150528)]          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               15052900  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 15,058,205\n",
      "Trainable params: 15,058,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "7l3EMzc5Ay9q",
    "outputId": "248fe727-6cdc-4e17-e78c-717e3f310a26"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(dense_nn,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nimnuSjqGu1"
   },
   "source": [
    "# TASK 4: Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8I89tUIq_fr"
   },
   "source": [
    "Decide the Learning Rate, Optimizer, Loss Function and Metrics to be used and justify why they were chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1K3LuRDk5R9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "dense_nn.compile(loss='categorical_crossentropy',optimizer=Adam(1e-6),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3iy9obAqKcT"
   },
   "source": [
    "# TASK 5: Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBOSFeDRqOaN"
   },
   "source": [
    "Fit the model to the data by dividing the train data into train and validation set in a ratio of 80:20. Decide the number of epochs and ensure overfitting doesn’t occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ve-6KMYyhtuW",
    "outputId": "d2d4c140-9f5a-4dca-8819-0486569bc630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "103/103 [==============================] - 2s 23ms/step - loss: 1.5677 - accuracy: 0.2795 - val_loss: 1.5060 - val_accuracy: 0.3595\n",
      "Epoch 2/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.4739 - accuracy: 0.3578 - val_loss: 1.4583 - val_accuracy: 0.3748\n",
      "Epoch 3/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.4339 - accuracy: 0.3893 - val_loss: 1.4408 - val_accuracy: 0.3974\n",
      "Epoch 4/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.4017 - accuracy: 0.4103 - val_loss: 1.4434 - val_accuracy: 0.3509\n",
      "Epoch 5/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.3753 - accuracy: 0.4342 - val_loss: 1.3817 - val_accuracy: 0.4366\n",
      "Epoch 6/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.3490 - accuracy: 0.4403 - val_loss: 1.3714 - val_accuracy: 0.4329\n",
      "Epoch 7/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.3319 - accuracy: 0.4543 - val_loss: 1.3518 - val_accuracy: 0.4434\n",
      "Epoch 8/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.3136 - accuracy: 0.4675 - val_loss: 1.3563 - val_accuracy: 0.4213\n",
      "Epoch 9/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.3002 - accuracy: 0.4796 - val_loss: 1.3318 - val_accuracy: 0.4544\n",
      "Epoch 10/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.2886 - accuracy: 0.4837 - val_loss: 1.3668 - val_accuracy: 0.4072\n",
      "Epoch 11/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.2765 - accuracy: 0.4866 - val_loss: 1.3376 - val_accuracy: 0.4287\n",
      "Epoch 12/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.2610 - accuracy: 0.4961 - val_loss: 1.3248 - val_accuracy: 0.4581\n",
      "Epoch 13/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.2492 - accuracy: 0.5018 - val_loss: 1.3104 - val_accuracy: 0.4660\n",
      "Epoch 14/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.2354 - accuracy: 0.5178 - val_loss: 1.3135 - val_accuracy: 0.4611\n",
      "Epoch 15/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.2222 - accuracy: 0.5181 - val_loss: 1.2941 - val_accuracy: 0.4691\n",
      "Epoch 16/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.2110 - accuracy: 0.5249 - val_loss: 1.2937 - val_accuracy: 0.4642\n",
      "Epoch 17/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.2121 - accuracy: 0.5198 - val_loss: 1.2863 - val_accuracy: 0.4832\n",
      "Epoch 18/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.1979 - accuracy: 0.5292 - val_loss: 1.2851 - val_accuracy: 0.4789\n",
      "Epoch 19/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.1870 - accuracy: 0.5413 - val_loss: 1.2883 - val_accuracy: 0.4630\n",
      "Epoch 20/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 1.1902 - accuracy: 0.5370 - val_loss: 1.2830 - val_accuracy: 0.4703\n",
      "Epoch 21/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1703 - accuracy: 0.5466 - val_loss: 1.2698 - val_accuracy: 0.4874\n",
      "Epoch 22/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1608 - accuracy: 0.5630 - val_loss: 1.2664 - val_accuracy: 0.4862\n",
      "Epoch 23/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1515 - accuracy: 0.5609 - val_loss: 1.2955 - val_accuracy: 0.4427\n",
      "Epoch 24/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1552 - accuracy: 0.5514 - val_loss: 1.2612 - val_accuracy: 0.4844\n",
      "Epoch 25/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1491 - accuracy: 0.5517 - val_loss: 1.2530 - val_accuracy: 0.4954\n",
      "Epoch 26/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1394 - accuracy: 0.5603 - val_loss: 1.2576 - val_accuracy: 0.4881\n",
      "Epoch 27/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1252 - accuracy: 0.5711 - val_loss: 1.2669 - val_accuracy: 0.4887\n",
      "Epoch 28/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1412 - accuracy: 0.5647 - val_loss: 1.2494 - val_accuracy: 0.4905\n",
      "Epoch 29/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1172 - accuracy: 0.5776 - val_loss: 1.2460 - val_accuracy: 0.4966\n",
      "Epoch 30/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.1052 - accuracy: 0.5848 - val_loss: 1.2506 - val_accuracy: 0.4936\n",
      "Epoch 31/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0974 - accuracy: 0.5874 - val_loss: 1.2494 - val_accuracy: 0.4942\n",
      "Epoch 32/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0983 - accuracy: 0.5900 - val_loss: 1.2430 - val_accuracy: 0.5003\n",
      "Epoch 33/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0867 - accuracy: 0.5918 - val_loss: 1.2496 - val_accuracy: 0.4991\n",
      "Epoch 34/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0901 - accuracy: 0.5938 - val_loss: 1.2362 - val_accuracy: 0.5003\n",
      "Epoch 35/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0779 - accuracy: 0.5983 - val_loss: 1.2408 - val_accuracy: 0.4948\n",
      "Epoch 36/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0752 - accuracy: 0.6004 - val_loss: 1.2542 - val_accuracy: 0.4881\n",
      "Epoch 37/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0661 - accuracy: 0.6051 - val_loss: 1.2332 - val_accuracy: 0.5119\n",
      "Epoch 38/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0593 - accuracy: 0.6065 - val_loss: 1.2302 - val_accuracy: 0.4942\n",
      "Epoch 39/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0514 - accuracy: 0.6110 - val_loss: 1.2239 - val_accuracy: 0.5070\n",
      "Epoch 40/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0464 - accuracy: 0.6171 - val_loss: 1.2211 - val_accuracy: 0.4997\n",
      "Epoch 41/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0420 - accuracy: 0.6182 - val_loss: 1.2392 - val_accuracy: 0.4972\n",
      "Epoch 42/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0475 - accuracy: 0.6111 - val_loss: 1.2292 - val_accuracy: 0.5028\n",
      "Epoch 43/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0328 - accuracy: 0.6212 - val_loss: 1.2254 - val_accuracy: 0.5113\n",
      "Epoch 44/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0297 - accuracy: 0.6202 - val_loss: 1.2153 - val_accuracy: 0.5107\n",
      "Epoch 45/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0191 - accuracy: 0.6297 - val_loss: 1.2253 - val_accuracy: 0.4966\n",
      "Epoch 46/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0162 - accuracy: 0.6313 - val_loss: 1.2270 - val_accuracy: 0.5126\n",
      "Epoch 47/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0102 - accuracy: 0.6378 - val_loss: 1.2416 - val_accuracy: 0.4850\n",
      "Epoch 48/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0180 - accuracy: 0.6310 - val_loss: 1.2207 - val_accuracy: 0.4923\n",
      "Epoch 49/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0200 - accuracy: 0.6274 - val_loss: 1.2154 - val_accuracy: 0.5162\n",
      "Epoch 50/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 1.0028 - accuracy: 0.6352 - val_loss: 1.2223 - val_accuracy: 0.5021\n",
      "Epoch 51/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9915 - accuracy: 0.6460 - val_loss: 1.2313 - val_accuracy: 0.5052\n",
      "Epoch 52/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9992 - accuracy: 0.6425 - val_loss: 1.2140 - val_accuracy: 0.5156\n",
      "Epoch 53/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9937 - accuracy: 0.6414 - val_loss: 1.2074 - val_accuracy: 0.5015\n",
      "Epoch 54/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9831 - accuracy: 0.6476 - val_loss: 1.2233 - val_accuracy: 0.5150\n",
      "Epoch 55/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9786 - accuracy: 0.6485 - val_loss: 1.2037 - val_accuracy: 0.5119\n",
      "Epoch 56/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9653 - accuracy: 0.6584 - val_loss: 1.2055 - val_accuracy: 0.5162\n",
      "Epoch 57/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9641 - accuracy: 0.6617 - val_loss: 1.2002 - val_accuracy: 0.5156\n",
      "Epoch 58/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9653 - accuracy: 0.6592 - val_loss: 1.2079 - val_accuracy: 0.5113\n",
      "Epoch 59/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9539 - accuracy: 0.6681 - val_loss: 1.2047 - val_accuracy: 0.5126\n",
      "Epoch 60/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9600 - accuracy: 0.6594 - val_loss: 1.2030 - val_accuracy: 0.5297\n",
      "Epoch 61/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9563 - accuracy: 0.6653 - val_loss: 1.2101 - val_accuracy: 0.5107\n",
      "Epoch 62/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9461 - accuracy: 0.6656 - val_loss: 1.2026 - val_accuracy: 0.5126\n",
      "Epoch 63/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9427 - accuracy: 0.6698 - val_loss: 1.2111 - val_accuracy: 0.5224\n",
      "Epoch 64/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9426 - accuracy: 0.6728 - val_loss: 1.1983 - val_accuracy: 0.5187\n",
      "Epoch 65/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9322 - accuracy: 0.6753 - val_loss: 1.1952 - val_accuracy: 0.5175\n",
      "Epoch 66/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9262 - accuracy: 0.6840 - val_loss: 1.1953 - val_accuracy: 0.5230\n",
      "Epoch 67/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9220 - accuracy: 0.6848 - val_loss: 1.2085 - val_accuracy: 0.5193\n",
      "Epoch 68/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9294 - accuracy: 0.6781 - val_loss: 1.1926 - val_accuracy: 0.5138\n",
      "Epoch 69/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9184 - accuracy: 0.6830 - val_loss: 1.2016 - val_accuracy: 0.5181\n",
      "Epoch 70/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9188 - accuracy: 0.6808 - val_loss: 1.1956 - val_accuracy: 0.5199\n",
      "Epoch 71/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9115 - accuracy: 0.6857 - val_loss: 1.2623 - val_accuracy: 0.4764\n",
      "Epoch 72/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.9191 - accuracy: 0.6781 - val_loss: 1.2001 - val_accuracy: 0.5126\n",
      "Epoch 73/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.9032 - accuracy: 0.6894 - val_loss: 1.1915 - val_accuracy: 0.5211\n",
      "Epoch 74/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8968 - accuracy: 0.7004 - val_loss: 1.1964 - val_accuracy: 0.5254\n",
      "Epoch 75/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8991 - accuracy: 0.6905 - val_loss: 1.2032 - val_accuracy: 0.5162\n",
      "Epoch 76/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.9167 - accuracy: 0.6767 - val_loss: 1.1886 - val_accuracy: 0.5297\n",
      "Epoch 77/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8881 - accuracy: 0.6992 - val_loss: 1.1887 - val_accuracy: 0.5224\n",
      "Epoch 78/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8813 - accuracy: 0.7049 - val_loss: 1.2026 - val_accuracy: 0.5236\n",
      "Epoch 79/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8839 - accuracy: 0.6946 - val_loss: 1.1834 - val_accuracy: 0.5297\n",
      "Epoch 80/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8769 - accuracy: 0.7044 - val_loss: 1.2073 - val_accuracy: 0.5236\n",
      "Epoch 81/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8775 - accuracy: 0.7026 - val_loss: 1.1963 - val_accuracy: 0.5162\n",
      "Epoch 82/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8688 - accuracy: 0.7124 - val_loss: 1.2012 - val_accuracy: 0.5162\n",
      "Epoch 83/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8861 - accuracy: 0.6928 - val_loss: 1.1853 - val_accuracy: 0.5303\n",
      "Epoch 84/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8640 - accuracy: 0.7121 - val_loss: 1.1882 - val_accuracy: 0.5340\n",
      "Epoch 85/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8589 - accuracy: 0.7151 - val_loss: 1.1861 - val_accuracy: 0.5199\n",
      "Epoch 86/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8561 - accuracy: 0.7176 - val_loss: 1.1876 - val_accuracy: 0.5315\n",
      "Epoch 87/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8544 - accuracy: 0.7140 - val_loss: 1.1861 - val_accuracy: 0.5217\n",
      "Epoch 88/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8453 - accuracy: 0.7232 - val_loss: 1.1845 - val_accuracy: 0.5205\n",
      "Epoch 89/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8478 - accuracy: 0.7173 - val_loss: 1.1927 - val_accuracy: 0.5144\n",
      "Epoch 90/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8413 - accuracy: 0.7240 - val_loss: 1.1813 - val_accuracy: 0.5303\n",
      "Epoch 91/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8393 - accuracy: 0.7217 - val_loss: 1.1940 - val_accuracy: 0.5285\n",
      "Epoch 92/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8335 - accuracy: 0.7258 - val_loss: 1.1900 - val_accuracy: 0.5266\n",
      "Epoch 93/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8331 - accuracy: 0.7231 - val_loss: 1.1846 - val_accuracy: 0.5273\n",
      "Epoch 94/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8284 - accuracy: 0.7315 - val_loss: 1.1921 - val_accuracy: 0.5199\n",
      "Epoch 95/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8301 - accuracy: 0.7258 - val_loss: 1.1829 - val_accuracy: 0.5321\n",
      "Epoch 96/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8238 - accuracy: 0.7303 - val_loss: 1.1936 - val_accuracy: 0.5205\n",
      "Epoch 97/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8192 - accuracy: 0.7341 - val_loss: 1.1825 - val_accuracy: 0.5309\n",
      "Epoch 98/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8151 - accuracy: 0.7367 - val_loss: 1.1793 - val_accuracy: 0.5358\n",
      "Epoch 99/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8115 - accuracy: 0.7398 - val_loss: 1.1988 - val_accuracy: 0.5070\n",
      "Epoch 100/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8119 - accuracy: 0.7356 - val_loss: 1.1910 - val_accuracy: 0.5254\n",
      "Epoch 101/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8117 - accuracy: 0.7333 - val_loss: 1.1833 - val_accuracy: 0.5279\n",
      "Epoch 102/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.8021 - accuracy: 0.7412 - val_loss: 1.1851 - val_accuracy: 0.5352\n",
      "Epoch 103/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.8030 - accuracy: 0.7398 - val_loss: 1.1772 - val_accuracy: 0.5175\n",
      "Epoch 104/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7938 - accuracy: 0.7470 - val_loss: 1.1806 - val_accuracy: 0.5199\n",
      "Epoch 105/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7918 - accuracy: 0.7467 - val_loss: 1.1831 - val_accuracy: 0.5321\n",
      "Epoch 106/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7933 - accuracy: 0.7415 - val_loss: 1.1881 - val_accuracy: 0.5352\n",
      "Epoch 107/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7915 - accuracy: 0.7418 - val_loss: 1.1788 - val_accuracy: 0.5260\n",
      "Epoch 108/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7889 - accuracy: 0.7476 - val_loss: 1.1842 - val_accuracy: 0.5328\n",
      "Epoch 109/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7904 - accuracy: 0.7413 - val_loss: 1.1836 - val_accuracy: 0.5224\n",
      "Epoch 110/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7755 - accuracy: 0.7569 - val_loss: 1.1958 - val_accuracy: 0.5291\n",
      "Epoch 111/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7735 - accuracy: 0.7543 - val_loss: 1.1768 - val_accuracy: 0.5242\n",
      "Epoch 112/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7707 - accuracy: 0.7601 - val_loss: 1.2165 - val_accuracy: 0.5138\n",
      "Epoch 113/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7734 - accuracy: 0.7499 - val_loss: 1.1745 - val_accuracy: 0.5346\n",
      "Epoch 114/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7706 - accuracy: 0.7526 - val_loss: 1.1812 - val_accuracy: 0.5303\n",
      "Epoch 115/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7683 - accuracy: 0.7575 - val_loss: 1.1782 - val_accuracy: 0.5242\n",
      "Epoch 116/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7685 - accuracy: 0.7554 - val_loss: 1.1909 - val_accuracy: 0.5346\n",
      "Epoch 117/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7700 - accuracy: 0.7560 - val_loss: 1.1757 - val_accuracy: 0.5291\n",
      "Epoch 118/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7563 - accuracy: 0.7640 - val_loss: 1.1846 - val_accuracy: 0.5248\n",
      "Epoch 119/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7682 - accuracy: 0.7533 - val_loss: 1.1782 - val_accuracy: 0.5352\n",
      "Epoch 120/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7469 - accuracy: 0.7735 - val_loss: 1.1728 - val_accuracy: 0.5315\n",
      "Epoch 121/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7445 - accuracy: 0.7741 - val_loss: 1.1715 - val_accuracy: 0.5260\n",
      "Epoch 122/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7421 - accuracy: 0.7744 - val_loss: 1.1767 - val_accuracy: 0.5395\n",
      "Epoch 123/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7419 - accuracy: 0.7727 - val_loss: 1.1829 - val_accuracy: 0.5340\n",
      "Epoch 124/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7524 - accuracy: 0.7641 - val_loss: 1.1769 - val_accuracy: 0.5285\n",
      "Epoch 125/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7357 - accuracy: 0.7787 - val_loss: 1.1878 - val_accuracy: 0.5389\n",
      "Epoch 126/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7323 - accuracy: 0.7796 - val_loss: 1.1725 - val_accuracy: 0.5279\n",
      "Epoch 127/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7302 - accuracy: 0.7836 - val_loss: 1.1786 - val_accuracy: 0.5260\n",
      "Epoch 128/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7301 - accuracy: 0.7813 - val_loss: 1.1889 - val_accuracy: 0.5358\n",
      "Epoch 129/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7278 - accuracy: 0.7801 - val_loss: 1.1913 - val_accuracy: 0.5144\n",
      "Epoch 130/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7322 - accuracy: 0.7761 - val_loss: 1.1724 - val_accuracy: 0.5364\n",
      "Epoch 131/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7171 - accuracy: 0.7868 - val_loss: 1.1805 - val_accuracy: 0.5156\n",
      "Epoch 132/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7194 - accuracy: 0.7830 - val_loss: 1.1708 - val_accuracy: 0.5303\n",
      "Epoch 133/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7170 - accuracy: 0.7868 - val_loss: 1.1757 - val_accuracy: 0.5450\n",
      "Epoch 134/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7148 - accuracy: 0.7889 - val_loss: 1.1822 - val_accuracy: 0.5370\n",
      "Epoch 135/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7122 - accuracy: 0.7903 - val_loss: 1.2022 - val_accuracy: 0.5260\n",
      "Epoch 136/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7285 - accuracy: 0.7733 - val_loss: 1.1726 - val_accuracy: 0.5389\n",
      "Epoch 137/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7067 - accuracy: 0.7943 - val_loss: 1.1658 - val_accuracy: 0.5279\n",
      "Epoch 138/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7047 - accuracy: 0.7938 - val_loss: 1.1701 - val_accuracy: 0.5395\n",
      "Epoch 139/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.7113 - accuracy: 0.7909 - val_loss: 1.1771 - val_accuracy: 0.5346\n",
      "Epoch 140/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6961 - accuracy: 0.7984 - val_loss: 1.1713 - val_accuracy: 0.5383\n",
      "Epoch 141/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6920 - accuracy: 0.8020 - val_loss: 1.1697 - val_accuracy: 0.5370\n",
      "Epoch 142/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6920 - accuracy: 0.8015 - val_loss: 1.1665 - val_accuracy: 0.5383\n",
      "Epoch 143/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6877 - accuracy: 0.8043 - val_loss: 1.1705 - val_accuracy: 0.5358\n",
      "Epoch 144/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6891 - accuracy: 0.7994 - val_loss: 1.1751 - val_accuracy: 0.5377\n",
      "Epoch 145/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6957 - accuracy: 0.7964 - val_loss: 1.1809 - val_accuracy: 0.5199\n",
      "Epoch 146/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6812 - accuracy: 0.8061 - val_loss: 1.1732 - val_accuracy: 0.5309\n",
      "Epoch 147/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6857 - accuracy: 0.8050 - val_loss: 1.1801 - val_accuracy: 0.5291\n",
      "Epoch 148/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6808 - accuracy: 0.8061 - val_loss: 1.1735 - val_accuracy: 0.5401\n",
      "Epoch 149/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6755 - accuracy: 0.8102 - val_loss: 1.1835 - val_accuracy: 0.5383\n",
      "Epoch 150/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6826 - accuracy: 0.8059 - val_loss: 1.1671 - val_accuracy: 0.5438\n",
      "Epoch 151/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6719 - accuracy: 0.8107 - val_loss: 1.1672 - val_accuracy: 0.5426\n",
      "Epoch 152/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6703 - accuracy: 0.8122 - val_loss: 1.1842 - val_accuracy: 0.5346\n",
      "Epoch 153/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6656 - accuracy: 0.8148 - val_loss: 1.1709 - val_accuracy: 0.5395\n",
      "Epoch 154/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6623 - accuracy: 0.8141 - val_loss: 1.1707 - val_accuracy: 0.5383\n",
      "Epoch 155/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6612 - accuracy: 0.8162 - val_loss: 1.1761 - val_accuracy: 0.5419\n",
      "Epoch 156/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6632 - accuracy: 0.8115 - val_loss: 1.1660 - val_accuracy: 0.5413\n",
      "Epoch 157/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6541 - accuracy: 0.8220 - val_loss: 1.1693 - val_accuracy: 0.5364\n",
      "Epoch 158/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6615 - accuracy: 0.8138 - val_loss: 1.1807 - val_accuracy: 0.5419\n",
      "Epoch 159/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6538 - accuracy: 0.8176 - val_loss: 1.1671 - val_accuracy: 0.5407\n",
      "Epoch 160/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6521 - accuracy: 0.8202 - val_loss: 1.1794 - val_accuracy: 0.5444\n",
      "Epoch 161/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6514 - accuracy: 0.8191 - val_loss: 1.1730 - val_accuracy: 0.5352\n",
      "Epoch 162/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6487 - accuracy: 0.8242 - val_loss: 1.1910 - val_accuracy: 0.5254\n",
      "Epoch 163/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6575 - accuracy: 0.8119 - val_loss: 1.1818 - val_accuracy: 0.5438\n",
      "Epoch 164/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6585 - accuracy: 0.8093 - val_loss: 1.1692 - val_accuracy: 0.5346\n",
      "Epoch 165/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6462 - accuracy: 0.8259 - val_loss: 1.1712 - val_accuracy: 0.5358\n",
      "Epoch 166/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6333 - accuracy: 0.8331 - val_loss: 1.1745 - val_accuracy: 0.5309\n",
      "Epoch 167/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6328 - accuracy: 0.8346 - val_loss: 1.1840 - val_accuracy: 0.5285\n",
      "Epoch 168/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6349 - accuracy: 0.8277 - val_loss: 1.1792 - val_accuracy: 0.5242\n",
      "Epoch 169/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6302 - accuracy: 0.8318 - val_loss: 1.1834 - val_accuracy: 0.5456\n",
      "Epoch 170/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6406 - accuracy: 0.8191 - val_loss: 1.1745 - val_accuracy: 0.5426\n",
      "Epoch 171/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6260 - accuracy: 0.8335 - val_loss: 1.1764 - val_accuracy: 0.5419\n",
      "Epoch 172/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6242 - accuracy: 0.8389 - val_loss: 1.1763 - val_accuracy: 0.5401\n",
      "Epoch 173/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6249 - accuracy: 0.8321 - val_loss: 1.1687 - val_accuracy: 0.5334\n",
      "Epoch 174/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6206 - accuracy: 0.8357 - val_loss: 1.1673 - val_accuracy: 0.5364\n",
      "Epoch 175/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6178 - accuracy: 0.8366 - val_loss: 1.1729 - val_accuracy: 0.5260\n",
      "Epoch 176/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6160 - accuracy: 0.8378 - val_loss: 1.1726 - val_accuracy: 0.5419\n",
      "Epoch 177/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.6130 - accuracy: 0.8403 - val_loss: 1.1685 - val_accuracy: 0.5389\n",
      "Epoch 178/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6082 - accuracy: 0.8461 - val_loss: 1.1685 - val_accuracy: 0.5395\n",
      "Epoch 179/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6308 - accuracy: 0.8233 - val_loss: 1.1838 - val_accuracy: 0.5279\n",
      "Epoch 180/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6165 - accuracy: 0.8353 - val_loss: 1.1683 - val_accuracy: 0.5370\n",
      "Epoch 181/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6021 - accuracy: 0.8433 - val_loss: 1.1732 - val_accuracy: 0.5358\n",
      "Epoch 182/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6068 - accuracy: 0.8399 - val_loss: 1.1732 - val_accuracy: 0.5395\n",
      "Epoch 183/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.6003 - accuracy: 0.8427 - val_loss: 1.1671 - val_accuracy: 0.5395\n",
      "Epoch 184/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5958 - accuracy: 0.8487 - val_loss: 1.1755 - val_accuracy: 0.5377\n",
      "Epoch 185/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5955 - accuracy: 0.8507 - val_loss: 1.1847 - val_accuracy: 0.5389\n",
      "Epoch 186/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5925 - accuracy: 0.8502 - val_loss: 1.1719 - val_accuracy: 0.5346\n",
      "Epoch 187/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5929 - accuracy: 0.8530 - val_loss: 1.1849 - val_accuracy: 0.5364\n",
      "Epoch 188/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5935 - accuracy: 0.8465 - val_loss: 1.1702 - val_accuracy: 0.5450\n",
      "Epoch 189/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5923 - accuracy: 0.8476 - val_loss: 1.1692 - val_accuracy: 0.5462\n",
      "Epoch 190/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5897 - accuracy: 0.8501 - val_loss: 1.1687 - val_accuracy: 0.5456\n",
      "Epoch 191/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5897 - accuracy: 0.8511 - val_loss: 1.1720 - val_accuracy: 0.5285\n",
      "Epoch 192/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5869 - accuracy: 0.8513 - val_loss: 1.1713 - val_accuracy: 0.5383\n",
      "Epoch 193/200\n",
      "103/103 [==============================] - 2s 19ms/step - loss: 0.5811 - accuracy: 0.8557 - val_loss: 1.1684 - val_accuracy: 0.5370\n",
      "Epoch 194/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5770 - accuracy: 0.8560 - val_loss: 1.1775 - val_accuracy: 0.5377\n",
      "Epoch 195/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5831 - accuracy: 0.8553 - val_loss: 1.1799 - val_accuracy: 0.5407\n",
      "Epoch 196/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5903 - accuracy: 0.8441 - val_loss: 1.1865 - val_accuracy: 0.5358\n",
      "Epoch 197/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5948 - accuracy: 0.8399 - val_loss: 1.1757 - val_accuracy: 0.5315\n",
      "Epoch 198/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5670 - accuracy: 0.8632 - val_loss: 1.1731 - val_accuracy: 0.5407\n",
      "Epoch 199/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5654 - accuracy: 0.8614 - val_loss: 1.1649 - val_accuracy: 0.5383\n",
      "Epoch 200/200\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 0.5670 - accuracy: 0.8651 - val_loss: 1.1728 - val_accuracy: 0.5370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ef0050080>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_nn.fit(X.reshape(X.shape[0],-1),y_dummy, epochs = 200, batch_size=64,validation_split = 0.2) #fit with 20# validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2XE23-MMOK8"
   },
   "outputs": [],
   "source": [
    "dense_nn.save(\"nn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W12VHx2zKD0j"
   },
   "source": [
    "# TASK 6: Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxVv_5CqKHF3"
   },
   "source": [
    "Use Tensorboard to display the accuracy and loss graphs of the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGG4oJycKHPx"
   },
   "source": [
    "# TASK 7: Building a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdFQawKeKHag"
   },
   "source": [
    "Build a Convolutional Neural Network (CNN) on the given dataset. Decide the number of convolution, pooling layers. Print a summary and architecture of the model. Explain the architecture. Perform all the steps applied on MLP and compare the performances of both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "SEhM0xHNK7Mr",
    "outputId": "a34a1940-37be-402f-a351-a06920d93022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 501765    \n",
      "=================================================================\n",
      "Total params: 9,906,757\n",
      "Trainable params: 9,906,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(224,224,3))\n",
    "m = Conv2D(64,(3,3),padding = \"same\") (input)\n",
    "m = Conv2D(64,(3,3),padding = \"same\", strides = 2) (m)\n",
    "m = Conv2D(128,(3,3),padding = \"same\") (m)\n",
    "m = Conv2D(128,(3,3),padding = \"same\", strides = 2) (m)\n",
    "m = Conv2D(256,(3,3),padding = \"same\") (m)\n",
    "m = Conv2D(256,(3,3),padding = \"same\") (m)\n",
    "m = Conv2D(512,(3,3),padding = \"same\", strides = 2) (m)\n",
    "m = Conv2D(512,(3,3),padding = \"same\") (m)\n",
    "m = Conv2D(512,(3,3),padding = \"same\") (m)\n",
    "m = Conv2D(512,(3,3),padding = \"same\", strides = 2) (m)\n",
    "m = Flatten()(m)\n",
    "m = Dense(K, activation = \"softmax\")(m)\n",
    "\n",
    "conv_model = Model(inputs= input, outputs = m)\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkxY59O3O13f"
   },
   "outputs": [],
   "source": [
    "conv_model.compile(loss = \"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R4LciP-RPF4i",
    "outputId": "de0a7f10-a11f-4d07-9c07-350b0355515d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/103 [..............................] - ETA: 10s - loss: 17.3644 - accuracy: 0.1797WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0742s vs `on_train_batch_end` time: 0.1351s). Check your callbacks.\n",
      "103/103 [==============================] - 25s 239ms/step - loss: 445.4943 - accuracy: 0.2175 - val_loss: 2.2223 - val_accuracy: 0.2076\n",
      "Epoch 2/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.6164 - accuracy: 0.2970 - val_loss: 2.1833 - val_accuracy: 0.2156\n",
      "Epoch 3/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.5903 - accuracy: 0.3301 - val_loss: 2.4280 - val_accuracy: 0.1911\n",
      "Epoch 4/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.5303 - accuracy: 0.3575 - val_loss: 1.6417 - val_accuracy: 0.3092\n",
      "Epoch 5/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4815 - accuracy: 0.3627 - val_loss: 1.4601 - val_accuracy: 0.3717\n",
      "Epoch 6/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4510 - accuracy: 0.3821 - val_loss: 1.6914 - val_accuracy: 0.3374\n",
      "Epoch 7/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4414 - accuracy: 0.3933 - val_loss: 2.7103 - val_accuracy: 0.2547\n",
      "Epoch 8/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.8330 - accuracy: 0.3233 - val_loss: 1.4190 - val_accuracy: 0.4127\n",
      "Epoch 9/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4096 - accuracy: 0.3887 - val_loss: 1.7223 - val_accuracy: 0.3043\n",
      "Epoch 10/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.5439 - accuracy: 0.3722 - val_loss: 1.4746 - val_accuracy: 0.3968\n",
      "Epoch 11/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4217 - accuracy: 0.4010 - val_loss: 1.3805 - val_accuracy: 0.4262\n",
      "Epoch 12/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3553 - accuracy: 0.4316 - val_loss: 1.5539 - val_accuracy: 0.3233\n",
      "Epoch 13/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3911 - accuracy: 0.4206 - val_loss: 1.4644 - val_accuracy: 0.3895\n",
      "Epoch 14/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3328 - accuracy: 0.4526 - val_loss: 1.5657 - val_accuracy: 0.3337\n",
      "Epoch 15/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3601 - accuracy: 0.4319 - val_loss: 1.4742 - val_accuracy: 0.3809\n",
      "Epoch 16/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3318 - accuracy: 0.4486 - val_loss: 1.4610 - val_accuracy: 0.3968\n",
      "Epoch 17/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3310 - accuracy: 0.4497 - val_loss: 1.3534 - val_accuracy: 0.4250\n",
      "Epoch 18/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3145 - accuracy: 0.4632 - val_loss: 1.3444 - val_accuracy: 0.4403\n",
      "Epoch 19/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2964 - accuracy: 0.4725 - val_loss: 1.4412 - val_accuracy: 0.4158\n",
      "Epoch 20/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.3088 - accuracy: 0.4724 - val_loss: 1.3250 - val_accuracy: 0.4623\n",
      "Epoch 21/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2774 - accuracy: 0.4776 - val_loss: 1.3662 - val_accuracy: 0.4336\n",
      "Epoch 22/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2860 - accuracy: 0.4739 - val_loss: 1.3333 - val_accuracy: 0.4532\n",
      "Epoch 23/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2677 - accuracy: 0.4860 - val_loss: 1.3599 - val_accuracy: 0.4562\n",
      "Epoch 24/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2460 - accuracy: 0.4982 - val_loss: 1.3334 - val_accuracy: 0.4519\n",
      "Epoch 25/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2455 - accuracy: 0.4979 - val_loss: 1.4812 - val_accuracy: 0.3484\n",
      "Epoch 26/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2431 - accuracy: 0.4985 - val_loss: 1.4969 - val_accuracy: 0.3509\n",
      "Epoch 27/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2480 - accuracy: 0.5004 - val_loss: 1.4944 - val_accuracy: 0.3919\n",
      "Epoch 28/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2977 - accuracy: 0.4694 - val_loss: 1.4536 - val_accuracy: 0.4152\n",
      "Epoch 29/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2664 - accuracy: 0.4782 - val_loss: 1.3823 - val_accuracy: 0.4274\n",
      "Epoch 30/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2158 - accuracy: 0.5134 - val_loss: 1.4100 - val_accuracy: 0.4060\n",
      "Epoch 31/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2185 - accuracy: 0.5134 - val_loss: 1.4234 - val_accuracy: 0.4256\n",
      "Epoch 32/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2701 - accuracy: 0.4909 - val_loss: 1.3704 - val_accuracy: 0.4464\n",
      "Epoch 33/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.2045 - accuracy: 0.5238 - val_loss: 1.3812 - val_accuracy: 0.4299\n",
      "Epoch 34/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.1760 - accuracy: 0.5289 - val_loss: 1.4347 - val_accuracy: 0.4023\n",
      "Epoch 35/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.1902 - accuracy: 0.5211 - val_loss: 1.3363 - val_accuracy: 0.4666\n",
      "Epoch 36/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.1356 - accuracy: 0.5581 - val_loss: 1.3860 - val_accuracy: 0.4458\n",
      "Epoch 37/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.1372 - accuracy: 0.5560 - val_loss: 1.3739 - val_accuracy: 0.4421\n",
      "Epoch 38/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.1196 - accuracy: 0.5610 - val_loss: 1.4857 - val_accuracy: 0.4311\n",
      "Epoch 39/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.1039 - accuracy: 0.5693 - val_loss: 1.3782 - val_accuracy: 0.4513\n",
      "Epoch 40/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.0691 - accuracy: 0.5846 - val_loss: 1.4154 - val_accuracy: 0.4354\n",
      "Epoch 41/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.0670 - accuracy: 0.5924 - val_loss: 1.4407 - val_accuracy: 0.4378\n",
      "Epoch 42/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.0345 - accuracy: 0.5952 - val_loss: 1.4231 - val_accuracy: 0.4630\n",
      "Epoch 43/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.9913 - accuracy: 0.6261 - val_loss: 1.5438 - val_accuracy: 0.4042\n",
      "Epoch 44/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.0589 - accuracy: 0.5926 - val_loss: 1.5024 - val_accuracy: 0.4158\n",
      "Epoch 45/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.9252 - accuracy: 0.6512 - val_loss: 1.6296 - val_accuracy: 0.4164\n",
      "Epoch 46/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.9471 - accuracy: 0.6424 - val_loss: 1.5672 - val_accuracy: 0.4201\n",
      "Epoch 47/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.9985 - accuracy: 0.6269 - val_loss: 1.8492 - val_accuracy: 0.3368\n",
      "Epoch 48/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.9158 - accuracy: 0.6601 - val_loss: 1.6379 - val_accuracy: 0.4127\n",
      "Epoch 49/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.7783 - accuracy: 0.7137 - val_loss: 1.7897 - val_accuracy: 0.4115\n",
      "Epoch 50/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.7184 - accuracy: 0.7384 - val_loss: 1.8096 - val_accuracy: 0.4140\n",
      "Epoch 51/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.7342 - accuracy: 0.7344 - val_loss: 1.8130 - val_accuracy: 0.4385\n",
      "Epoch 52/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.5160 - accuracy: 0.8278 - val_loss: 2.0651 - val_accuracy: 0.4170\n",
      "Epoch 53/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.3882 - accuracy: 0.8764 - val_loss: 2.4199 - val_accuracy: 0.4336\n",
      "Epoch 54/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.3075 - accuracy: 0.9015 - val_loss: 2.9320 - val_accuracy: 0.4005\n",
      "Epoch 55/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.6588 - accuracy: 0.7641 - val_loss: 2.5478 - val_accuracy: 0.3766\n",
      "Epoch 56/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.8112 - accuracy: 0.7203 - val_loss: 1.9984 - val_accuracy: 0.4299\n",
      "Epoch 57/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.3286 - accuracy: 0.8989 - val_loss: 2.5733 - val_accuracy: 0.4207\n",
      "Epoch 58/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.2394 - accuracy: 0.9240 - val_loss: 3.1527 - val_accuracy: 0.4152\n",
      "Epoch 59/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 3.8858 - val_accuracy: 0.4225\n",
      "Epoch 60/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.2501 - accuracy: 0.6597 - val_loss: 1.8379 - val_accuracy: 0.4091\n",
      "Epoch 61/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.3891 - accuracy: 0.8802 - val_loss: 2.4282 - val_accuracy: 0.4287\n",
      "Epoch 62/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.1820 - accuracy: 0.9565 - val_loss: 3.0489 - val_accuracy: 0.4109\n",
      "Epoch 63/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.0832 - accuracy: 0.9844 - val_loss: 3.6697 - val_accuracy: 0.4097\n",
      "Epoch 64/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0362 - accuracy: 0.9956 - val_loss: 4.2698 - val_accuracy: 0.4170\n",
      "Epoch 65/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.7236 - accuracy: 0.7857 - val_loss: 2.6034 - val_accuracy: 0.4103\n",
      "Epoch 66/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 0.2129 - accuracy: 0.9363 - val_loss: 3.1336 - val_accuracy: 0.4060\n",
      "Epoch 67/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0722 - accuracy: 0.9848 - val_loss: 3.8169 - val_accuracy: 0.4195\n",
      "Epoch 68/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0211 - accuracy: 0.9985 - val_loss: 4.2677 - val_accuracy: 0.4195\n",
      "Epoch 69/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0080 - accuracy: 0.9998 - val_loss: 4.6081 - val_accuracy: 0.4176\n",
      "Epoch 70/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.8479 - val_accuracy: 0.4182\n",
      "Epoch 71/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.0390 - val_accuracy: 0.4231\n",
      "Epoch 72/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.2172 - val_accuracy: 0.4213\n",
      "Epoch 73/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.3703 - val_accuracy: 0.4250\n",
      "Epoch 74/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.5149 - val_accuracy: 0.4219\n",
      "Epoch 75/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.6383 - val_accuracy: 0.4250\n",
      "Epoch 76/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 9.1588e-04 - accuracy: 1.0000 - val_loss: 5.7585 - val_accuracy: 0.4256\n",
      "Epoch 77/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.8594e-04 - accuracy: 1.0000 - val_loss: 5.8741 - val_accuracy: 0.4250\n",
      "Epoch 78/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.7482e-04 - accuracy: 1.0000 - val_loss: 5.9780 - val_accuracy: 0.4238\n",
      "Epoch 79/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.8677e-04 - accuracy: 1.0000 - val_loss: 6.0753 - val_accuracy: 0.4250\n",
      "Epoch 80/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.1355e-04 - accuracy: 1.0000 - val_loss: 6.1671 - val_accuracy: 0.4256\n",
      "Epoch 81/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.5352e-04 - accuracy: 1.0000 - val_loss: 6.2552 - val_accuracy: 0.4250\n",
      "Epoch 82/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.0357e-04 - accuracy: 1.0000 - val_loss: 6.3469 - val_accuracy: 0.4225\n",
      "Epoch 83/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.5968e-04 - accuracy: 1.0000 - val_loss: 6.4276 - val_accuracy: 0.4219\n",
      "Epoch 84/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.2148e-04 - accuracy: 1.0000 - val_loss: 6.5066 - val_accuracy: 0.4231\n",
      "Epoch 85/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.8872e-04 - accuracy: 1.0000 - val_loss: 6.5829 - val_accuracy: 0.4238\n",
      "Epoch 86/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.6041e-04 - accuracy: 1.0000 - val_loss: 6.6580 - val_accuracy: 0.4219\n",
      "Epoch 87/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 2.4191e-04 - accuracy: 1.0000 - val_loss: 6.7394 - val_accuracy: 0.4219\n",
      "Epoch 88/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.1478e-04 - accuracy: 1.0000 - val_loss: 6.8100 - val_accuracy: 0.4207\n",
      "Epoch 89/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.9485e-04 - accuracy: 1.0000 - val_loss: 6.8782 - val_accuracy: 0.4225\n",
      "Epoch 90/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.7740e-04 - accuracy: 1.0000 - val_loss: 6.9453 - val_accuracy: 0.4219\n",
      "Epoch 91/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.6193e-04 - accuracy: 1.0000 - val_loss: 7.0126 - val_accuracy: 0.4231\n",
      "Epoch 92/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.4825e-04 - accuracy: 1.0000 - val_loss: 7.0790 - val_accuracy: 0.4231\n",
      "Epoch 93/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3573e-04 - accuracy: 1.0000 - val_loss: 7.1434 - val_accuracy: 0.4238\n",
      "Epoch 94/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.2454e-04 - accuracy: 1.0000 - val_loss: 7.2062 - val_accuracy: 0.4238\n",
      "Epoch 95/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.1522e-04 - accuracy: 1.0000 - val_loss: 7.2723 - val_accuracy: 0.4219\n",
      "Epoch 96/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.0547e-04 - accuracy: 1.0000 - val_loss: 7.3317 - val_accuracy: 0.4207\n",
      "Epoch 97/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 9.7094e-05 - accuracy: 1.0000 - val_loss: 7.3928 - val_accuracy: 0.4213\n",
      "Epoch 98/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.9510e-05 - accuracy: 1.0000 - val_loss: 7.4523 - val_accuracy: 0.4207\n",
      "Epoch 99/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.2773e-05 - accuracy: 1.0000 - val_loss: 7.5123 - val_accuracy: 0.4201\n",
      "Epoch 100/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.6573e-05 - accuracy: 1.0000 - val_loss: 7.5727 - val_accuracy: 0.4201\n",
      "Epoch 101/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.0830e-05 - accuracy: 1.0000 - val_loss: 7.6300 - val_accuracy: 0.4201\n",
      "Epoch 102/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.5786e-05 - accuracy: 1.0000 - val_loss: 7.6865 - val_accuracy: 0.4201\n",
      "Epoch 103/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.0796e-05 - accuracy: 1.0000 - val_loss: 7.7412 - val_accuracy: 0.4213\n",
      "Epoch 104/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 5.6339e-05 - accuracy: 1.0000 - val_loss: 7.7981 - val_accuracy: 0.4213\n",
      "Epoch 105/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 5.2322e-05 - accuracy: 1.0000 - val_loss: 7.8538 - val_accuracy: 0.4213\n",
      "Epoch 106/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.8608e-05 - accuracy: 1.0000 - val_loss: 7.9094 - val_accuracy: 0.4207\n",
      "Epoch 107/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 4.5177e-05 - accuracy: 1.0000 - val_loss: 7.9630 - val_accuracy: 0.4207\n",
      "Epoch 108/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.2066e-05 - accuracy: 1.0000 - val_loss: 8.0180 - val_accuracy: 0.4207\n",
      "Epoch 109/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.9130e-05 - accuracy: 1.0000 - val_loss: 8.0711 - val_accuracy: 0.4207\n",
      "Epoch 110/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.6461e-05 - accuracy: 1.0000 - val_loss: 8.1247 - val_accuracy: 0.4207\n",
      "Epoch 111/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 3.3997e-05 - accuracy: 1.0000 - val_loss: 8.1779 - val_accuracy: 0.4219\n",
      "Epoch 112/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.1676e-05 - accuracy: 1.0000 - val_loss: 8.2310 - val_accuracy: 0.4207\n",
      "Epoch 113/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.9561e-05 - accuracy: 1.0000 - val_loss: 8.2835 - val_accuracy: 0.4213\n",
      "Epoch 114/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.7565e-05 - accuracy: 1.0000 - val_loss: 8.3359 - val_accuracy: 0.4213\n",
      "Epoch 115/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.5744e-05 - accuracy: 1.0000 - val_loss: 8.3889 - val_accuracy: 0.4219\n",
      "Epoch 116/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.4042e-05 - accuracy: 1.0000 - val_loss: 8.4395 - val_accuracy: 0.4219\n",
      "Epoch 117/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.2434e-05 - accuracy: 1.0000 - val_loss: 8.4910 - val_accuracy: 0.4213\n",
      "Epoch 118/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.1054e-05 - accuracy: 1.0000 - val_loss: 8.5430 - val_accuracy: 0.4219\n",
      "Epoch 119/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.9644e-05 - accuracy: 1.0000 - val_loss: 8.5947 - val_accuracy: 0.4219\n",
      "Epoch 120/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.8366e-05 - accuracy: 1.0000 - val_loss: 8.6461 - val_accuracy: 0.4213\n",
      "Epoch 121/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.7172e-05 - accuracy: 1.0000 - val_loss: 8.6960 - val_accuracy: 0.4207\n",
      "Epoch 122/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.6090e-05 - accuracy: 1.0000 - val_loss: 8.7448 - val_accuracy: 0.4207\n",
      "Epoch 123/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.5045e-05 - accuracy: 1.0000 - val_loss: 8.7949 - val_accuracy: 0.4207\n",
      "Epoch 124/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.4068e-05 - accuracy: 1.0000 - val_loss: 8.8436 - val_accuracy: 0.4207\n",
      "Epoch 125/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3173e-05 - accuracy: 1.0000 - val_loss: 8.8950 - val_accuracy: 0.4207\n",
      "Epoch 126/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.2343e-05 - accuracy: 1.0000 - val_loss: 8.9442 - val_accuracy: 0.4195\n",
      "Epoch 127/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.1579e-05 - accuracy: 1.0000 - val_loss: 8.9966 - val_accuracy: 0.4195\n",
      "Epoch 128/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.0841e-05 - accuracy: 1.0000 - val_loss: 9.0464 - val_accuracy: 0.4195\n",
      "Epoch 129/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.0152e-05 - accuracy: 1.0000 - val_loss: 9.0953 - val_accuracy: 0.4195\n",
      "Epoch 130/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 9.5246e-06 - accuracy: 1.0000 - val_loss: 9.1441 - val_accuracy: 0.4195\n",
      "Epoch 131/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.9262e-06 - accuracy: 1.0000 - val_loss: 9.1926 - val_accuracy: 0.4189\n",
      "Epoch 132/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.3679e-06 - accuracy: 1.0000 - val_loss: 9.2419 - val_accuracy: 0.4195\n",
      "Epoch 133/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.8589e-06 - accuracy: 1.0000 - val_loss: 9.2903 - val_accuracy: 0.4195\n",
      "Epoch 134/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 7.3627e-06 - accuracy: 1.0000 - val_loss: 9.3399 - val_accuracy: 0.4195\n",
      "Epoch 135/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.9113e-06 - accuracy: 1.0000 - val_loss: 9.3904 - val_accuracy: 0.4195\n",
      "Epoch 136/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.4801e-06 - accuracy: 1.0000 - val_loss: 9.4384 - val_accuracy: 0.4195\n",
      "Epoch 137/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.0785e-06 - accuracy: 1.0000 - val_loss: 9.4864 - val_accuracy: 0.4195\n",
      "Epoch 138/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.7076e-06 - accuracy: 1.0000 - val_loss: 9.5338 - val_accuracy: 0.4189\n",
      "Epoch 139/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.3770e-06 - accuracy: 1.0000 - val_loss: 9.5852 - val_accuracy: 0.4189\n",
      "Epoch 140/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.0313e-06 - accuracy: 1.0000 - val_loss: 9.6325 - val_accuracy: 0.4189\n",
      "Epoch 141/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.7207e-06 - accuracy: 1.0000 - val_loss: 9.6802 - val_accuracy: 0.4182\n",
      "Epoch 142/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.4282e-06 - accuracy: 1.0000 - val_loss: 9.7283 - val_accuracy: 0.4189\n",
      "Epoch 143/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.1599e-06 - accuracy: 1.0000 - val_loss: 9.7764 - val_accuracy: 0.4189\n",
      "Epoch 144/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.9079e-06 - accuracy: 1.0000 - val_loss: 9.8238 - val_accuracy: 0.4189\n",
      "Epoch 145/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.6725e-06 - accuracy: 1.0000 - val_loss: 9.8716 - val_accuracy: 0.4189\n",
      "Epoch 146/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.4488e-06 - accuracy: 1.0000 - val_loss: 9.9179 - val_accuracy: 0.4189\n",
      "Epoch 147/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.2437e-06 - accuracy: 1.0000 - val_loss: 9.9669 - val_accuracy: 0.4182\n",
      "Epoch 148/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.0458e-06 - accuracy: 1.0000 - val_loss: 10.0133 - val_accuracy: 0.4182\n",
      "Epoch 149/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.8612e-06 - accuracy: 1.0000 - val_loss: 10.0618 - val_accuracy: 0.4182\n",
      "Epoch 150/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.6909e-06 - accuracy: 1.0000 - val_loss: 10.1086 - val_accuracy: 0.4170\n",
      "Epoch 151/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.5295e-06 - accuracy: 1.0000 - val_loss: 10.1553 - val_accuracy: 0.4170\n",
      "Epoch 152/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.3797e-06 - accuracy: 1.0000 - val_loss: 10.2025 - val_accuracy: 0.4170\n",
      "Epoch 153/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.2394e-06 - accuracy: 1.0000 - val_loss: 10.2507 - val_accuracy: 0.4182\n",
      "Epoch 154/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.1035e-06 - accuracy: 1.0000 - val_loss: 10.2974 - val_accuracy: 0.4164\n",
      "Epoch 155/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.9788e-06 - accuracy: 1.0000 - val_loss: 10.3448 - val_accuracy: 0.4164\n",
      "Epoch 156/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.8588e-06 - accuracy: 1.0000 - val_loss: 10.3921 - val_accuracy: 0.4164\n",
      "Epoch 157/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.7488e-06 - accuracy: 1.0000 - val_loss: 10.4376 - val_accuracy: 0.4164\n",
      "Epoch 158/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 1.6461e-06 - accuracy: 1.0000 - val_loss: 10.4852 - val_accuracy: 0.4164\n",
      "Epoch 159/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.5543e-06 - accuracy: 1.0000 - val_loss: 10.5380 - val_accuracy: 0.4170\n",
      "Epoch 160/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.4576e-06 - accuracy: 1.0000 - val_loss: 10.5840 - val_accuracy: 0.4164\n",
      "Epoch 161/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3703e-06 - accuracy: 1.0000 - val_loss: 10.6299 - val_accuracy: 0.4164\n",
      "Epoch 162/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.2887e-06 - accuracy: 1.0000 - val_loss: 10.6773 - val_accuracy: 0.4176\n",
      "Epoch 163/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.2117e-06 - accuracy: 1.0000 - val_loss: 10.7243 - val_accuracy: 0.4176\n",
      "Epoch 164/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.1396e-06 - accuracy: 1.0000 - val_loss: 10.7702 - val_accuracy: 0.4182\n",
      "Epoch 165/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.0725e-06 - accuracy: 1.0000 - val_loss: 10.8166 - val_accuracy: 0.4182\n",
      "Epoch 166/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.0086e-06 - accuracy: 1.0000 - val_loss: 10.8628 - val_accuracy: 0.4189\n",
      "Epoch 167/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 9.5236e-07 - accuracy: 1.0000 - val_loss: 10.9109 - val_accuracy: 0.4189\n",
      "Epoch 168/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.9472e-07 - accuracy: 1.0000 - val_loss: 10.9571 - val_accuracy: 0.4189\n",
      "Epoch 169/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 8.4206e-07 - accuracy: 1.0000 - val_loss: 11.0023 - val_accuracy: 0.4182\n",
      "Epoch 170/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.9223e-07 - accuracy: 1.0000 - val_loss: 11.0491 - val_accuracy: 0.4189\n",
      "Epoch 171/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.4492e-07 - accuracy: 1.0000 - val_loss: 11.0957 - val_accuracy: 0.4182\n",
      "Epoch 172/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 7.0278e-07 - accuracy: 1.0000 - val_loss: 11.1421 - val_accuracy: 0.4189\n",
      "Epoch 173/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.6057e-07 - accuracy: 1.0000 - val_loss: 11.1882 - val_accuracy: 0.4195\n",
      "Epoch 174/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 6.2210e-07 - accuracy: 1.0000 - val_loss: 11.2337 - val_accuracy: 0.4189\n",
      "Epoch 175/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.8500e-07 - accuracy: 1.0000 - val_loss: 11.2804 - val_accuracy: 0.4195\n",
      "Epoch 176/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.5235e-07 - accuracy: 1.0000 - val_loss: 11.3281 - val_accuracy: 0.4189\n",
      "Epoch 177/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 5.1768e-07 - accuracy: 1.0000 - val_loss: 11.3724 - val_accuracy: 0.4189\n",
      "Epoch 178/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.8781e-07 - accuracy: 1.0000 - val_loss: 11.4182 - val_accuracy: 0.4189\n",
      "Epoch 179/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.5896e-07 - accuracy: 1.0000 - val_loss: 11.4630 - val_accuracy: 0.4189\n",
      "Epoch 180/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.3265e-07 - accuracy: 1.0000 - val_loss: 11.5076 - val_accuracy: 0.4189\n",
      "Epoch 181/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 4.0718e-07 - accuracy: 1.0000 - val_loss: 11.5527 - val_accuracy: 0.4189\n",
      "Epoch 182/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.8324e-07 - accuracy: 1.0000 - val_loss: 11.5984 - val_accuracy: 0.4189\n",
      "Epoch 183/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.6062e-07 - accuracy: 1.0000 - val_loss: 11.6429 - val_accuracy: 0.4189\n",
      "Epoch 184/200\n",
      "103/103 [==============================] - 24s 231ms/step - loss: 3.4028e-07 - accuracy: 1.0000 - val_loss: 11.6877 - val_accuracy: 0.4189\n",
      "Epoch 185/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.2067e-07 - accuracy: 1.0000 - val_loss: 11.7340 - val_accuracy: 0.4189\n",
      "Epoch 186/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 3.0272e-07 - accuracy: 1.0000 - val_loss: 11.7804 - val_accuracy: 0.4195\n",
      "Epoch 187/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.8452e-07 - accuracy: 1.0000 - val_loss: 11.8254 - val_accuracy: 0.4189\n",
      "Epoch 188/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.6823e-07 - accuracy: 1.0000 - val_loss: 11.8691 - val_accuracy: 0.4195\n",
      "Epoch 189/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.5211e-07 - accuracy: 1.0000 - val_loss: 11.9135 - val_accuracy: 0.4195\n",
      "Epoch 190/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.3924e-07 - accuracy: 1.0000 - val_loss: 11.9605 - val_accuracy: 0.4195\n",
      "Epoch 191/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.2462e-07 - accuracy: 1.0000 - val_loss: 12.0038 - val_accuracy: 0.4195\n",
      "Epoch 192/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 2.1224e-07 - accuracy: 1.0000 - val_loss: 12.0471 - val_accuracy: 0.4195\n",
      "Epoch 193/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.9891e-07 - accuracy: 1.0000 - val_loss: 12.0927 - val_accuracy: 0.4195\n",
      "Epoch 194/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.8709e-07 - accuracy: 1.0000 - val_loss: 12.1372 - val_accuracy: 0.4195\n",
      "Epoch 195/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.7658e-07 - accuracy: 1.0000 - val_loss: 12.1812 - val_accuracy: 0.4195\n",
      "Epoch 196/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.6710e-07 - accuracy: 1.0000 - val_loss: 12.2258 - val_accuracy: 0.4195\n",
      "Epoch 197/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.5677e-07 - accuracy: 1.0000 - val_loss: 12.2702 - val_accuracy: 0.4195\n",
      "Epoch 198/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.4833e-07 - accuracy: 1.0000 - val_loss: 12.3157 - val_accuracy: 0.4195\n",
      "Epoch 199/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3911e-07 - accuracy: 1.0000 - val_loss: 12.3591 - val_accuracy: 0.4195\n",
      "Epoch 200/200\n",
      "103/103 [==============================] - 24s 230ms/step - loss: 1.3142e-07 - accuracy: 1.0000 - val_loss: 12.4025 - val_accuracy: 0.4195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa51e072b00>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(X,y_dummy, epochs = 200, batch_size=64,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTPmLO1CKYl6"
   },
   "source": [
    "# TASK 8: Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d92Hp-8gKY0S"
   },
   "source": [
    "Apply a minimum of two different optimization techniques on both models (CNN and MLP) e.g. including Dropouts in-between, and list down any performance improvements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv6YNxZ4KZAW"
   },
   "source": [
    "# TASK 9: Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7415OWoKZMz"
   },
   "source": [
    "Use the model that is performing better to predict over new_test_data. Please pay attention to the class labels, since your predictions will be evaluated against the same labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueYshzw6CCJa"
   },
   "outputs": [],
   "source": [
    "ptm = VGG16(\n",
    "    input_shape= list(IMAGE_SIZE)+[3], #add color channel\n",
    "    weights = \"imagenet\", #weights trained on imagenet\n",
    "    include_top = False) #Dont include flatten nor dense\n",
    "\n",
    "ptm.trainable = False #Freeze pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "9dCXpZCRSIYc",
    "outputId": "bebd29bf-23b5-4501-97c4-e9e42694ca2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 125445    \n",
      "=================================================================\n",
      "Total params: 14,840,133\n",
      "Trainable params: 125,445\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(224,224,3))\n",
    "x = ptm.layers[1](input) #assuming you are ignoring the first conv layer as implied in your code\n",
    "for layer in ptm.layers[2:]:\n",
    "    x = layer(x)\n",
    "\n",
    "m = Flatten()(x)\n",
    "m = Dense(len(y_dummy.columns),activation = \"softmax\")(m)\n",
    "\n",
    "model = Model(inputs = input, outputs = m)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wteuKru6SPVl"
   },
   "outputs": [],
   "source": [
    "gen_train = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDGWJxUnS9wx"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GuQQTH1S-_p"
   },
   "outputs": [],
   "source": [
    "train_generator = gen_train.flow(\n",
    "  X, y = y_dummy,\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JP330Jk4S_IK"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = \"adam\",\n",
    "    metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--5wgjhvHkAH"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "7-jZEWg-Tpn3",
    "outputId": "cc656419-1c56-48f7-bc35-9444cb4ace28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 82s 1s/step - loss: 0.5072 - accuracy: 0.8103\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 80s 1s/step - loss: 0.3587 - accuracy: 0.8689\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 81s 1s/step - loss: 0.3194 - accuracy: 0.8831\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 82s 1s/step - loss: 0.2733 - accuracy: 0.9014\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 81s 1s/step - loss: 0.2669 - accuracy: 0.9032\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 79s 1s/step - loss: 0.2479 - accuracy: 0.9079\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 77s 1s/step - loss: 0.2427 - accuracy: 0.9112\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 78s 1s/step - loss: 0.2250 - accuracy: 0.9188\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 77s 1s/step - loss: 0.2132 - accuracy: 0.9264\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 77s 1s/step - loss: 0.1918 - accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 80s 1s/step - loss: 0.1953 - accuracy: 0.9315\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 79s 1s/step - loss: 0.1871 - accuracy: 0.9296\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1804 - accuracy: 0.9337\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 76s 1s/step - loss: 0.1839 - accuracy: 0.9343\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 76s 1s/step - loss: 0.1639 - accuracy: 0.9395\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1682 - accuracy: 0.9378\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1784 - accuracy: 0.9302\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1724 - accuracy: 0.9357\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1731 - accuracy: 0.9338\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.1554 - accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    steps_per_epoch = int(np.ceil(len(image_files)/batch_size))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "S25gPAWlT1M-",
    "outputId": "69d91091-7bea-4322-82ff-0499b748a91b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "#plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "_Z1Vk7eWT7gA",
    "outputId": "5e3ad857-9e27-4ff5-ba37-8398591afb61"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "#plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xRHYrQKGFql"
   },
   "outputs": [],
   "source": [
    "model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVn6U-lHWSTX"
   },
   "outputs": [],
   "source": [
    "X_t = np.array([cv2.resize(cv2.imread(x,1),IMAGE_SIZE) for x in test_image_files])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "z8E_k91vS2yz",
    "outputId": "cc2ec80f-92a0-4e5f-8567-d8e297d478ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 224, 224, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu41yY0EZuXn"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(X_t).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nlrJc9JQgcg"
   },
   "outputs": [],
   "source": [
    "predict2 = pd.Series(predict).map(lambda x: y_dummy.columns[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eoC0TETRNEg"
   },
   "outputs": [],
   "source": [
    "files = pd.Series(test_image_files).map(lambda x: x.replace(\"animal_dataset_intermediate/test/\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vv7k9ZdaRhdX"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([files,predict2]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsSNG5mNRpdi"
   },
   "outputs": [],
   "source": [
    "df2.columns = [\"filename\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SimeI_rZhJR1"
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"animal_dataset_intermediate/Testing_set_animals.csv\").merge(df2, on = \"filename\").drop(\"target\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "O0H7CI4TjFTN",
    "outputId": "21a2b90f-7869-411d-d498-925b5ceeb615"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_38fc06b3-4060-4da0-8524-2b3eb16eb17d\", \"predictions.csv\", 60125)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3.to_csv(\"predictions.csv\",index=False)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUF9HKdRTawN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Assigment 2 - Intermediate.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
